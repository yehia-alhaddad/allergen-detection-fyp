{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Image Preprocessing and OCR\n",
    "\n",
    "This notebook handles image preprocessing and text extraction using the SimpleOCREngine for optimal quality and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure local src/ modules are importable from notebook context\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "SRC = ROOT / 'src'\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.append(str(SRC))\n",
    "    print(f\"Added to sys.path: {SRC}\")\n",
    "else:\n",
    "    print(f\"sys.path already contains: {SRC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A: Setup and Environment Configuration\n",
    "\n",
    "Configure environment and import necessary libraries for image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q opencv-python pytesseract easyocr pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Utility Functions for Preprocessing\n",
    "\n",
    "Define helper functions for image preprocessing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define directories\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA = ROOT / 'data'\n",
    "RAW_IMAGES = DATA / 'raw'\n",
    "OCR_OUTPUT = DATA / 'ocr_results'\n",
    "OCR_RAW_TEXT = OCR_OUTPUT / 'raw_text'\n",
    "OCR_CLEAN_TEXT = OCR_OUTPUT / 'cleaned_text'\n",
    "\n",
    "# Create output directories\n",
    "OCR_RAW_TEXT.mkdir(parents=True, exist_ok=True)\n",
    "OCR_CLEAN_TEXT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load annotations\n",
    "annotations_path = DATA / 'annotations.csv'\n",
    "df = pd.read_csv(annotations_path)\n",
    "\n",
    "# Load allergen dictionary\n",
    "import json\n",
    "allergen_dict_path = DATA / 'allergen_dictionary.json'\n",
    "with open(allergen_dict_path, 'r', encoding='utf-8') as f:\n",
    "    allergen_dict = json.load(f)\n",
    "\n",
    "print(f\"âœ“ Project root: {ROOT}\")\n",
    "print(f\"âœ“ Raw images: {RAW_IMAGES}\")\n",
    "print(f\"âœ“ OCR output: {OCR_OUTPUT}\")\n",
    "print(f\"âœ“ Allergen dictionary loaded: {len(allergen_dict)} classes\")\n",
    "print(f\"\\nðŸ“Š Dataset loaded:\")\n",
    "print(f\"   Total products: {len(df)}\")\n",
    "print(f\"   Columns: {', '.join(df.columns.tolist())}\")\n",
    "print(f\"\\nFirst 3 products:\")\n",
    "print(df[['code', 'product_name', 'allergens']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section B: Text Extraction with SimpleOCREngine\n",
    "\n",
    "Extract text from preprocessed images using the SimpleOCREngine for high-quality OCR results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(ROOT / 'src'))\n",
    "\n",
    "from preprocessing.ocr_preprocessor import prepare_for_ocr, generate_preprocessed_variants\n",
    "from ocr.hybrid_extractor import HybridOCREngine\n",
    "from ocr.easyocr_extractor import EasyOCREngine\n",
    "from ocr.ocr_postprocessor import clean_text, normalize_ocr_noise, quality_score\n",
    "from allergen_detection.synonym_mapper import SynonymMapper\n",
    "\n",
    "# Configuration\n",
    "USE_HYBRID = True  # Use hybrid OCR with multi-pass preprocessing\n",
    "BATCH_SIZE = 10  # Progress update frequency\n",
    "\n",
    "# Initialize OCR engine\n",
    "if USE_HYBRID:\n",
    "    ocr_engine = HybridOCREngine(\n",
    "        lang_list=['en'], \n",
    "        try_easyocr=True, \n",
    "        try_tesseract=False  # Set to True if Tesseract is installed\n",
    "    )\n",
    "    print(\"âœ“ Hybrid OCR engine initialized (multi-pass preprocessing + confidence scoring)\")\n",
    "else:\n",
    "    ocr_engine = EasyOCREngine(\n",
    "        lang_list=['en'],\n",
    "        contrast_ths=0.3,\n",
    "        adjust_contrast=0.7,\n",
    "        mag_ratio=1.5\n",
    "    )\n",
    "    print(\"âœ“ EasyOCR engine initialized\")\n",
    "\n",
    "# Initialize allergen synonym mapper\n",
    "allergen_mapper = SynonymMapper(allergen_dict)\n",
    "print(\"âœ“ Allergen synonym mapper loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Sample Images and Extract Text\n",
    "\n",
    "Run OCR on product images and save extracted text with quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from allergen_detection.product_matcher import ProductNameMatcher\n",
    "\n",
    "# Initialize product matcher\n",
    "product_matcher = ProductNameMatcher(df, confidence_threshold=0.70)\n",
    "\n",
    "class HybridAllergenDetector:\n",
    "    \"\"\"Hybrid detector combining product matching + ingredient text OCR with advanced preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, product_matcher, ingredient_mapper, ocr_engine):\n",
    "        self.product_matcher = product_matcher\n",
    "        self.ingredient_mapper = ingredient_mapper\n",
    "        self.ocr_engine = ocr_engine\n",
    "    \n",
    "    def detect(self, image, image_file):\n",
    "        \"\"\"Intelligent detection with multi-pass OCR and quality scoring\"\"\"\n",
    "        \n",
    "        # Use hybrid OCR engine (tries multiple preprocessing variants)\n",
    "        if hasattr(self.ocr_engine, 'extract_with_meta'):\n",
    "            ocr_result = self.ocr_engine.extract_with_meta(image)\n",
    "            ocr_text = ocr_result.get('text', '')\n",
    "            ocr_quality = ocr_result.get('quality_score', 0.0)\n",
    "            ocr_engine_used = ocr_result.get('engine', 'unknown')\n",
    "            ocr_variant = ocr_result.get('variant', 'unknown')\n",
    "        else:\n",
    "            preprocessed = prepare_for_ocr(image)\n",
    "            ocr_text = self.ocr_engine.extract(preprocessed)\n",
    "            ocr_quality = 0.0\n",
    "            ocr_engine_used = 'standard'\n",
    "            ocr_variant = 'default'\n",
    "        \n",
    "        # Apply normalization\n",
    "        ocr_clean = normalize_ocr_noise(clean_text(ocr_text))\n",
    "        \n",
    "        # Try product name matching\n",
    "        result_product = self.product_matcher.detect_from_image(image, self.ocr_engine)\n",
    "        product_confidence = result_product['confidence']\n",
    "        product_allergens = result_product['allergens']\n",
    "        \n",
    "        # Try ingredient text OCR\n",
    "        ingredient_allergens = self.ingredient_mapper.match(ocr_clean)\n",
    "        \n",
    "        # Intelligent fallback logic\n",
    "        if product_confidence >= 0.70 and product_allergens:\n",
    "            strategy = 'product_match'\n",
    "            allergens = product_allergens\n",
    "        elif ingredient_allergens:\n",
    "            strategy = 'ingredient_text'\n",
    "            allergens = ingredient_allergens\n",
    "        elif product_allergens:\n",
    "            strategy = 'product_match_low_conf'\n",
    "            allergens = product_allergens\n",
    "        else:\n",
    "            strategy = 'no_match'\n",
    "            allergens = set()\n",
    "        \n",
    "        return {\n",
    "            'allergens': allergens,\n",
    "            'strategy': strategy,\n",
    "            'raw_text': ocr_text,\n",
    "            'cleaned_text': ocr_clean,\n",
    "            'ocr_quality': ocr_quality,\n",
    "            'ocr_engine': ocr_engine_used,\n",
    "            'ocr_variant': ocr_variant\n",
    "        }\n",
    "\n",
    "# Initialize hybrid detector\n",
    "hybrid_detector = HybridAllergenDetector(product_matcher, allergen_mapper, ocr_engine)\n",
    "\n",
    "# Create output directories\n",
    "output_dirs = {\n",
    "    'raw_text': str(OCR_RAW_TEXT),\n",
    "    'cleaned_text': str(OCR_CLEAN_TEXT),\n",
    "    'allergen_matches': str(OCR_OUTPUT / 'allergen_matches'),\n",
    "}\n",
    "for dir_path in output_dirs.values():\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Process all images\n",
    "raw_image_dir = str(RAW_IMAGES)\n",
    "image_files = sorted([f for f in os.listdir(raw_image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "print(f\"Found {len(image_files)} images to process\")\n",
    "\n",
    "results = []\n",
    "errors = []\n",
    "strategy_counts = {}\n",
    "quality_stats = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "for idx, image_file in enumerate(image_files, 1):\n",
    "    try:\n",
    "        image_path = os.path.join(raw_image_dir, image_file)\n",
    "        filename_base = os.path.splitext(image_file)[0]\n",
    "        \n",
    "        # Load and process image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            errors.append(f\"{image_file}: Failed to read\")\n",
    "            continue\n",
    "        \n",
    "        # Run hybrid detection\n",
    "        detection = hybrid_detector.detect(image, image_file)\n",
    "        allergens = detection['allergens']\n",
    "        strategy = detection['strategy']\n",
    "        raw_text = detection['raw_text']\n",
    "        cleaned_text = detection['cleaned_text']\n",
    "        ocr_quality = detection.get('ocr_quality', 0.0)\n",
    "        \n",
    "        # Track statistics\n",
    "        strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "        quality_stats.append(ocr_quality)\n",
    "        \n",
    "        # Save outputs\n",
    "        with open(os.path.join(output_dirs['raw_text'], f\"{filename_base}.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(raw_text)\n",
    "        \n",
    "        with open(os.path.join(output_dirs['cleaned_text'], f\"{filename_base}.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned_text)\n",
    "        \n",
    "        with open(os.path.join(output_dirs['allergen_matches'], f\"{filename_base}.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'allergens': list(allergens),\n",
    "                'strategy': strategy,\n",
    "                'ocr_quality': ocr_quality,\n",
    "                'ocr_engine': detection.get('ocr_engine', 'unknown'),\n",
    "                'ocr_variant': detection.get('ocr_variant', 'unknown')\n",
    "            }, f)\n",
    "        \n",
    "        results.append({\n",
    "            'filename': image_file,\n",
    "            'allergens_found': list(allergens),\n",
    "            'strategy': strategy,\n",
    "            'text_length': len(cleaned_text),\n",
    "            'ocr_quality': ocr_quality\n",
    "        })\n",
    "        \n",
    "        # Progress update\n",
    "        if idx % BATCH_SIZE == 0:\n",
    "            elapsed = (datetime.now() - start_time).total_seconds()\n",
    "            rate = idx / elapsed\n",
    "            avg_quality = sum(quality_stats) / len(quality_stats) if quality_stats else 0.0\n",
    "            print(f\"[{idx}/{len(image_files)}] {rate:.1f} img/s | Avg quality: {avg_quality:.3f} | Strategies: {strategy_counts}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        errors.append(f\"{image_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C: Quality Assessment and Results\n",
    "\n",
    "Analyze OCR quality and compare with baseline approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Statistics\n",
    "allergen_found_count = sum(1 for r in results if r['allergens_found'])\n",
    "all_allergens = []\n",
    "for r in results:\n",
    "    all_allergens.extend(r['allergens_found'])\n",
    "\n",
    "allergen_freq = Counter(all_allergens)\n",
    "\n",
    "# Strategy effectiveness\n",
    "strategy_with_allergens = {}\n",
    "for r in results:\n",
    "    strategy = r['strategy']\n",
    "    if r['allergens_found']:\n",
    "        strategy_with_allergens[strategy] = strategy_with_allergens.get(strategy, 0) + 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYBRID DETECTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDetection Statistics:\")\n",
    "print(f\"  Total images: {len(results)}\")\n",
    "print(f\"  Images with allergens: {allergen_found_count} ({allergen_found_count/len(results)*100:.1f}%)\")\n",
    "print(f\"  Total allergen mentions: {len(all_allergens)}\")\n",
    "\n",
    "print(f\"\\nStrategy Effectiveness (% that found allergens):\")\n",
    "for strategy in sorted(strategy_with_allergens.keys()):\n",
    "    count_total = sum(1 for r in results if r['strategy'] == strategy)\n",
    "    count_with_allergens = strategy_with_allergens[strategy]\n",
    "    rate = count_with_allergens / count_total * 100 if count_total > 0 else 0\n",
    "    print(f\"  {strategy:25s}: {count_with_allergens:4d}/{count_total:4d} ({rate:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop 8 Detected Allergens:\")\n",
    "for allergen, count in allergen_freq.most_common(8):\n",
    "    print(f\"  - {allergen:15s}: {count:5d} occurrences\")\n",
    "\n",
    "print(f\"\\nProcessing Performance:\")\n",
    "print(f\"  Average text length: {sum(r['text_length'] for r in results) / len(results):.0f} chars\")\n",
    "print(f\"  Avg allergens per image: {len(all_allergens) / len(results):.2f}\")\n",
    "\n",
    "# Sample results\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE RESULTS (3 random images with allergens)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "samples = [r for r in results if r['allergens_found']]\n",
    "if samples:\n",
    "    for sample in random.sample(samples, min(3, len(samples))):\n",
    "        print(f\"\\n{sample['filename']}\")\n",
    "        print(f\"  Strategy: {sample['strategy']}\")\n",
    "        print(f\"  Allergens: {', '.join(sample['allergens_found'])}\")\n",
    "        print(f\"  Text length: {sample['text_length']} chars\")\n",
    "\n",
    "# Save analysis summary\n",
    "summary = {\n",
    "    'total_images': len(results),\n",
    "    'images_with_allergens': allergen_found_count,\n",
    "    'allergen_detection_rate': allergen_found_count / len(results),\n",
    "    'total_allergen_mentions': len(all_allergens),\n",
    "    'top_allergens': dict(allergen_freq.most_common(10)),\n",
    "    'strategy_distribution': strategy_counts,\n",
    "    'strategy_effectiveness': strategy_with_allergens,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "summary_path = str(OCR_OUTPUT / 'processing_summary.json')\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n[OK] Summary saved: data/ocr_results/processing_summary.json\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
